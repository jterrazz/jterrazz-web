![](assets/thumbnail.jpg)

# Ma√Ætriser la gestion de la m√©moire : j'ai cod√© mon propre malloc, et vous devriez essayer

Vous √™tes-vous d√©j√† demand√© comment votre ordinateur jongle avec des milliers de milliards d'octets chaque seconde ? ü§π‚Äç‚ôÇÔ∏è C'est une question qui m'a toujours fascin√©. J'ai donc d√©cid√© de soulever le capot et de plonger dans l'un des √©l√©ments les plus fondamentaux du puzzle : **l'allocation dynamique de m√©moire**.

Dans cet article, je vais vous expliquer pourquoi `malloc` existe, comment il fonctionne en profondeur, et comment j'ai construit ma propre version de z√©ro en utilisant l'appel syst√®me `mmap`. Si cela semble complexe, ne vous inqui√©tez pas. Je vais tout d√©construire √† partir des premiers principes. Pour moi, comprendre cela a √©t√© un v√©ritable d√©clic. Et si vous voulez mettre les mains dans le cambouis, mon [projet complet est sur GitHub](https://github.com/jterrazz/42-malloc). C'est parti. üöÄ

```c
// Voici les fonctions que nous allons construire.
void  malloc(size_t size);
void  free(void* ptr);
void  realloc(void* ptr, size_t size);
void  calloc(size_t count, size_t size);

// C'est ainsi que nous demanderons de la m√©moire √† l'OS.
#include <sys/mman.h>

void* mmap(void* addr, size_t len, int prot, int flags, int fd, off_t offset);
int   munmap(void* addr, size_t len);

// Et ceci nous aide √† fixer quelques r√®gles de base.
#include <sys/resource.h>

int   getrlimit(int resource, struct rlimit* rlp);
int   setrlimit(int resource, const struct rlimit* rlp);
```

## La m√©moire : le rigide, l'√©ph√©m√®re et l'√† la demande

Touchons rapidement un mot sur la fa√ßon dont le C g√®re normalement la m√©moire. C'est un syst√®me assez rigide.

- **Variables statiques et globales** : Elles sont grav√©es dans le marbre lors de la compilation. Elles existent du moment o√π le programme d√©marre jusqu'√† la seconde o√π il s'arr√™te, vivant aux c√¥t√©s du code lui-m√™me.
- **Variables automatiques** : Ce sont celles √† l'int√©rieur des fonctions. Elles sont cr√©√©es sur la "stack" (pile) lorsqu'une fonction est appel√©e et disparaissent d√®s que la fonction se termine.

Cela fonctionne, mais avec deux limites majeures :

1. **Vous devez conna√Ætre la taille de tout √† l'avance.** Impossible de cr√©er un tableau et de d√©cider de sa taille plus tard.
2. **Vous √™tes coinc√© avec une dur√©e de vie fixe.** La m√©moire dure soit pour toujours, soit le temps d'un appel de fonction. Rien entre les deux.

C'est pourquoi nous avons besoin de l'allocation dynamique. C'est pour toutes les situations o√π vous ne connaissez ni le "quoi" ni le "quand" au moment de la compilation.

### L'outil puissant du noyau : `mmap`

```c
#include <sys/mman.h>

void* mmap(void* addr, size_t len, int prot, int flags, int fd, off_t offset);
```

Alors, comment obtenir de la m√©moire √† la demande ? Nous devons demander au syst√®me d'exploitation. Le noyau fournit un outil puissant pour cela appel√© un **appel syst√®me**. Celui sur lequel je me suis concentr√© est `mmap()`. Voyez-le comme une ligne directe vers l'OS, lui demandant de r√©server un morceau de m√©moire physique et de le mapper √† une adresse virtuelle dans notre programme. C'est la source ultime de m√©moire. üåå

Il existe un autre outil appel√© `sbrk`, mais pour ce projet, `mmap` est notre arme de choix. Il est incroyablement flexible pour g√©rer les r√©gions m√©moire.

### Si `mmap` est la source, pourquoi s'emb√™ter avec `malloc` ?

C'√©tait ma premi√®re grande interrogation. Si `mmap` nous donne de la m√©moire, pourquoi ne pas simplement l'appeler chaque fois que nous avons besoin d'une nouvelle variable ?

La r√©ponse est la performance. Les appels syst√®me sont co√ªteux. Ils n√©cessitent un changement de contexte de votre programme vers le noyau, ce qui est une op√©ration lente. La plupart des applications demandent et lib√®rent de petits bouts de m√©moire des milliers de fois par seconde. Si chacune de ces demandes √©tait un appel syst√®me complet, nos programmes seraient incroyablement lents.

C'est l√† que `malloc` intervient. C'est un interm√©diaire astucieux. Au lieu d'aller voir le noyau pour chaque petite chose, `malloc` y va une fois et demande un √©norme bloc de m√©moire. Ensuite, il g√®re ce bloc pour vous. Quand vous demandez un peu de m√©moire, `malloc` d√©coupe simplement une tranche du bloc qu'il d√©tient d√©j√†. Oui, cela ajoute un peu de surcharge (la biblioth√®que `malloc` elle-m√™me utilise de la m√©moire), mais le gain de vitesse est √©norme. C'est un compromis d'ing√©nierie classique.

## Construisons la chose : mon impl√©mentation

### La biblioth√®que : la bo√Æte √† outils m√©moire

Ma biblioth√®que `malloc` fournit le trio classique :

- `malloc` : Demande un bloc de m√©moire et renvoie un pointeur vers celui-ci.
- `free` : Reprend ce pointeur quand vous avez fini et marque la m√©moire comme disponible.
- `realloc` : Vous permet de redimensionner un bloc de m√©moire d√©j√† allou√©, en conservant les donn√©es d'origine.

### La structure de donn√©es : mon organisation de la m√©moire

Pour faire fonctionner cela, je devais d√©cider comment garder une trace de tout. J'ai opt√© pour une hi√©rarchie √† deux niveaux :

- **Heap (Tas)** : Une grande r√©gion de m√©moire que je demande √† l'OS via `mmap`.
- **Block (Bloc)** : Un morceau plus petit d'un tas que je distribue quand `malloc` est appel√©.

Les deux ont besoin de m√©tadonn√©es. Je place un petit en-t√™te au d√©but de chaque tas et de chaque bloc pour stocker des informations. Apr√®s un seul appel `malloc`, la carte m√©moire ressemble √† ceci :

![Structure Heap et Block](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iXHfrEUza03cFe5IXEvs0Q.png)

Voici les `structs` C que j'ai d√©finies pour ces m√©tadonn√©es :

```c
// M√©tadonn√©es pour toute une r√©gion mmap'√©e
typedef struct s_heap {
  struct s_heap   *prev;
  struct s_heap   *next;
  t_heap_group    group; // TINY, SMALL, ou LARGE
  size_t          total_size;
  size_t          free_size;
  size_t          block_count;
} t_heap;

// M√©tadonn√©es pour un seul bloc allou√©
typedef struct s_block {
  struct s_block  *prev;
  struct s_block  *next;
  size_t          data_size;
  bool            freed;
} t_block;
```

En donnant √† chaque bloc des pointeurs `next` et `prev`, j'ai effectivement cr√©√© une liste cha√Æn√©e. Cela me permet de parcourir le tas pour trouver des espaces libres ou pour trouver les voisins d'un bloc que je veux lib√©rer (`free`).

Ces petites macros servaient d'aides pour sauter rapidement du d√©but d'un tas ou d'un bloc vers la zone de donn√©es utilisateur.

```c
#define HEAP_SHIFT(start)   ((void*)start + sizeof(t_heap))
#define BLOCK_SHIFT(start)  ((void*)start + sizeof(t_block))
```

### Strat√©gie de performance : toutes les allocations ne se valent pas

J'ai vite r√©alis√© que traiter une allocation de 10 octets de la m√™me mani√®re qu'une de 10 m√©gaoctets √©tait une mauvaise id√©e. Pour optimiser, j'ai cr√©√© trois cat√©gories : `TINY`, `SMALL` et `LARGE`. Ma strat√©gie √©tait de pr√©-allouer des pages m√©moire pour les requ√™tes `TINY` et `SMALL`, en visant √† faire tenir au moins 100 blocs dans chaque tas. Les blocs `LARGE` sont l'exception ; ils sont allou√©s au coup par coup sans pr√©-allocation car ils sont g√©n√©ralement rares.

Une petite astuce de pro que j'ai apprise : il est bien plus efficace de dimensionner vos tas comme un multiple de la taille de page du syst√®me. Vous pouvez l'obtenir avec `getpagesize()` (ou `getconf PAGE_SIZE` dans le terminal). Sur ma machine, c'est 4096 octets.

J'ai donc fait quelques calculs pour d√©finir les tailles de mes tas :

```c
// Une page peut contenir 128 blocs minuscules (tiny)
#define  TINY_HEAP_ALLOCATION_SIZE   (4 * getpagesize())
#define  TINY_BLOCK_SIZE             (TINY_HEAP_ALLOCATION_SIZE / 128)

// Quatre pages peuvent contenir 128 petits blocs (small)
#define  SMALL_HEAP_ALLOCATION_SIZE  (16 * getpagesize())
#define  SMALL_BLOCK_SIZE            (SMALL_HEAP_ALLOCATION_SIZE / 128)
```

### L'algorithme `malloc` : trouver une place pour les donn√©es

Quand un appel `malloc` arrive, voici la logique que mon code suit :

1. Il regarde d'abord un pointeur global pour voir si des tas existent d√©j√†.
2. Il parcourt ensuite la liste des tas, cherchant un bloc libre assez grand. J'ai utilis√© la strat√©gie du **first-fit** (premier adapt√©) : prendre le premier qui convient. C'est simple et rapide.
3. S'il arrive √† la fin d'un tas et qu'il reste de la place, il y ajoute simplement un nouveau bloc.
4. Si le dernier tas est totalement plein, il est temps de demander plus de terrain √† l'OS en appelant `mmap`.

```c
// L'appel syst√®me pour cr√©er un nouveau tas.
void *heap = (t_heap *)mmap(NULL, heap_size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);
```

### `free` et le probl√®me de la fragmentation

![Fragmentation M√©moire](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y7xikxHO1Yoyv1eZm7l6aA.png)

Quand `free` est appel√©, marquer simplement un bloc comme "disponible" est facile, mais cela cr√©e un probl√®me appel√© **fragmentation**. Vous vous retrouvez avec plein de petits trous inutiles dans votre m√©moire, comme une partie de Tetris qui a mal tourn√©.

Pour combattre cela, j'ai impl√©ment√© quelques strat√©gies cl√©s :

- **Fusion (Coalescing) :** Quand un bloc est lib√©r√©, je v√©rifie si ses voisins sont aussi libres. Si c'est le cas, je les fusionne en un seul bloc libre plus grand.
- **Rendre la m√©moire :** Si le bloc lib√©r√© est le tout dernier d'un tas, et que j'ai d'autres tas disponibles, je rel√¢che simplement le tas vide entier √† l'OS avec `munmap`. Aucun int√©r√™t √† garder de la m√©moire vide.

```c
// Rendre la m√©moire au noyau.
munmap(heap, heap->total_size);
```

### `realloc` : le m√©tamorphe

`realloc` se r√©sume souvent √† une recette simple : `malloc` un nouveau bloc de la taille d√©sir√©e, `memcpy` les donn√©es de l'ancien bloc vers le nouveau, puis `free` l'ancien bloc.

Un cas particulier √† conna√Ætre est `realloc(ptr, 0)`. Le comportement ici peut varier. J'ai adopt√© une approche "paresseuse" en renvoyant simplement le pointeur d'origine. Sachez cependant que certains standards disent que cela devrait √©quivaloir √† `free(ptr)`. Mon conseil : n'utilisez pas `realloc` pour `free` de la m√©moire. Utilisez le bon outil pour le job.

## Mise √† l'√©preuve

La partie la plus gratifiante a √©t√© de voir mon `malloc` faire tourner des programmes r√©els. J'ai √©crit un petit script pour forcer le linker dynamique √† charger ma biblioth√®que au lieu de celle standard du syst√®me.

```sh
#!/bin/sh
export DYLD_LIBRARY_PATH=.
export DYLD_INSERT_LIBRARIES=libft_malloc.so
export DYLD_FORCE_FLAT_NAMESPACE=1
$@
```

Sauvegarder ceci en `run.sh` m'a permis de faire des choses comme `sh run.sh ls -l` ou `sh run.sh vim` et de voir si √ßa marchait.

### Le crash de `vim` et la le√ßon sur l'alignement

Et bien s√ªr, tout n'a pas march√© du premier coup. `ls` passait, mais lancer `vim` causait imm√©diatement une "segmentation fault". Que se passait-il ?

Le coupable √©tait **l'alignement m√©moire**. Il s'est av√©r√© que le `malloc` standard sur macOS (o√π je testais) ne renvoie pas n'importe quel pointeur. Il garantit que l'adresse est un multiple de 16. Certains programmes et instructions comptent l√†-dessus pour la performance. Mon `malloc` ne le faisait pas, et `vim` plantait.

La correction fut une astuce binaire simple mais puissante : `size = (size + 15) & ~15;`. Cette seule ligne assure que la taille est toujours un multiple de 16, et donc que l'adresse retourn√©e sera correctement align√©e. Une le√ßon cruciale.

Et voil√† l'aventure ! Nous sommes pass√©s de l'appel `mmap` du noyau jusqu'√† une biblioth√®que `malloc` fonctionnelle et test√©e. Pour moi, ce projet n'√©tait pas juste √©crire du code ; c'√©tait d√©mystifier une partie fondamentale du fonctionnement de nos machines.

C'√©tait un rappel puissant que la pratique est tout. Si vous voulez creuser plus loin, je vous encourage √† jeter un ≈ìil √† l'[impl√©mentation compl√®te sur mon GitHub](https://github.com/jterrazz/42-malloc). Forkez-le, cassez-le, et am√©liorez-le. Quand vous comprenez vraiment les fondations, vous gagnez le pouvoir de construire n'importe quoi par-dessus. Bon code.
