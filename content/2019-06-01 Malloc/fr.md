![](assets/thumbnail.jpg)

# Ma√Ætriser la Gestion De la M√©moire: J'ai Cr√©√© Mon Propre `malloc`, Et Vous Devriez En Faire Autant

Vous √™tes-vous d√©j√† demand√© comment votre ordinateur parvient √† brasser des milliers de milliards d'octets chaque seconde? ü§π‚Äç‚ôÇÔ∏è C'est une question qui m'a toujours fascin√©. J'ai donc d√©cid√© de soulever le voile pour plonger au c≈ìur de l'un des m√©canismes les plus fondamentaux: **l'allocation dynamique de m√©moire**.

Dans cet article, je vous emm√®ne avec moi √† la d√©couverte de `malloc`: pourquoi cette fonction existe, comment elle fonctionne dans ses moindres d√©tails, et comment j'en ai b√¢ti ma propre version √† partir de z√©ro en utilisant l'appel syst√®me `mmap`. Si cela vous semble complexe, n'ayez crainte. Nous allons tout d√©composer en partant des bases. Pour moi, comprendre ces rouages a √©t√© une v√©ritable r√©v√©lation. Et si vous souhaitez mettre les mains dans le cambouis, [mon projet est disponible sur GitHub](https://github.com/jterrazz/42-malloc). C'est parti! üöÄ

```c
// Voici les fonctions que nous allons r√©√©crire.
void  malloc(size_t size);
void  free(void* ptr);
void  realloc(void* ptr, size_t size);
void  calloc(size_t count, size_t size);

// C'est ainsi que nous demanderons de la m√©moire au syst√®me d'exploitation.
#include <sys/mman.h>

void* mmap(void* addr, size_t len, int prot, int flags, int fd, off_t offset);
int   munmap(void* addr, size_t len);

// Et ces fonctions nous aideront √† d√©finir quelques r√®gles du jeu.
#include <sys/resource.h>

int   getrlimit(int resource, struct rlimit* rlp);
int   setrlimit(int resource, const struct rlimit* rlp);
```

## La M√©moire: Le Rigide, L'√©ph√©m√®re Et Le Sur-mesure

Revenons rapidement sur la mani√®re dont le C g√®re traditionnellement la m√©moire. C'est un syst√®me plut√¥t rigide.

* **Les variables statiques et globales**: Leur sort est scell√© √† la compilation. Elles existent d√®s le lancement du programme jusqu'√† son arr√™t, cohabitant avec le code lui-m√™me.
* **Les variables automatiques**: Ce sont celles que l'on d√©clare dans les fonctions. Elles sont cr√©√©es sur la "stack" (la pile) lors d'un appel de fonction et s'√©vanouissent d√®s que la fonction se termine.

Ce syst√®me fonctionne, mais il pr√©sente deux limitations majeures:

1. **Il faut conna√Ætre la taille de chaque √©l√©ment √† l'avance.** Impossible de cr√©er un tableau et de d√©cider de sa taille plus tard.
2. **Leur dur√©e de vie est immuable.** La m√©moire allou√©e dure soit √©ternellement, soit le temps d'un appel de fonction. Rien entre les deux.

C'est pr√©cis√©ment l√† qu'intervient l'allocation dynamique. Elle est la solution pour toutes les situations o√π l'on ne conna√Æt ni le "quoi", ni le "quand" au moment de la compilation.

### L'outil Ultime Du Noyau: `mmap`

```c
#include <sys/mman.h>

void* mmap(void* addr, size_t len, int prot, int flags, int fd, off_t offset);
```

Alors, comment obtenir de la m√©moire √† la demande? Il faut en faire la requ√™te au syst√®me d'exploitation. Le noyau met √† notre disposition un outil puissant pour cela: un **appel syst√®me**. Celui sur lequel je me suis concentr√© est `mmap()`. Imaginez-le comme une ligne directe avec le syst√®me d'exploitation, pour lui demander de r√©server un bloc de m√©moire physique et de le "mapper" sur une adresse virtuelle dans notre programme. C'est la source de m√©moire ultime. üåå

Il existe un autre outil, `sbrk`, mais pour ce projet, `mmap` est notre arme de pr√©dilection. Sa flexibilit√© pour g√©rer des r√©gions de m√©moire est incomparable.

### Si `mmap` Est la Source, Pourquoi S'emb√™ter Avec `malloc`?

C'√©tait la premi√®re grande question que je me suis pos√©e. Si `mmap` nous fournit de la m√©moire, pourquoi ne pas simplement l'appeler chaque fois que nous avons besoin d'une nouvelle variable?

La r√©ponse tient en un mot: performance. Les appels syst√®me sont co√ªteux. Ils exigent une bascule de contexte (*context switch*) de votre programme vers le noyau, une op√©ration qui prend un temps pr√©cieux. La plupart des applications demandent et lib√®rent des petits morceaux de m√©moire des milliers de fois par seconde. Si chacune de ces requ√™tes √©tait un appel syst√®me √† part enti√®re, nos programmes s'effondreraient sous la charge.

C'est l√† que `malloc` entre en jeu. C'est un interm√©diaire astucieux. Au lieu que vous alliez voir le noyau pour la moindre broutille, `malloc` y va une seule fois pour demander un √©norme bloc de m√©moire. Ensuite, il g√®re ce bloc pour vous. Lorsque vous demandez un peu de m√©moire, `malloc` se contente de vous en d√©couper un morceau. Certes, cela ajoute une l√©g√®re surcouche (*overhead*)‚Äìla biblioth√®que `malloc` elle-m√™me consomme un peu de m√©moire‚Äìmais le gain de vitesse est colossal. C'est un compromis d'ing√©nierie classique.

## Passons √† la Construction: Mon Impl√©mentation

### La Biblioth√®que: la Bo√Æte √† Outils M√©moire

Ma biblioth√®que `malloc` fournit le trio classique:

* `malloc`: Demande un bloc de m√©moire et retourne un pointeur vers celui-ci.
* `free`: R√©cup√®re ce pointeur lorsque vous avez termin√© et marque la m√©moire comme disponible.
* `realloc`: Permet de redimensionner un bloc de m√©moire que vous avez d√©j√† allou√©, en conservant les donn√©es d'origine.

### La Structure De Donn√©es: Comment Organiser la M√©moire

Pour que tout cela fonctionne, je devais d√©cider comment tout orchestrer. J'ai opt√© pour une hi√©rarchie √† deux niveaux:

* **Heap**: Une grande r√©gion de m√©moire que je demande au syst√®me d'exploitation via `mmap`.
* **Block**: Un plus petit morceau d'un *heap*, que je distribue lorsqu'on appelle `malloc`.

Ces deux √©l√©ments ont besoin de quelques m√©tadonn√©es. J'ai donc plac√© un petit en-t√™te (*header*) au d√©but de chaque *heap* et de chaque *block* pour y stocker des informations. Apr√®s un simple appel √† `malloc`, la carte de la m√©moire ressemble √† ceci:

![Heap and Block Structure](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iXHfrEUza03cFe5IXEvs0Q.png)

Voici les `structs` C que j'ai d√©finies pour ces m√©tadonn√©es:

```c
// Metadata for a whole mmap'd region
typedef struct s_heap {
  struct s_heap   *prev;
  struct s_heap   *next;
  t_heap_group    group; // TINY, SMALL, or LARGE
  size_t          total_size;
  size_t          free_size;
  size_t          block_count;
} t_heap;

// Metadata for a single allocated block
typedef struct s_block {
  struct s_block  *prev;
  struct s_block  *next;
  size_t          data_size;
  bool            freed;
} t_block;
```

En dotant chaque bloc de pointeurs `next` et `prev`, j'ai de fait cr√©√© une liste cha√Æn√©e. Cela me permet de parcourir le *heap* pour trouver des emplacements libres ou pour retrouver les voisins d'un bloc que je souhaite lib√©rer avec `free`.

Ces petites macros m'ont servi de raccourcis pour passer rapidement du d√©but d'un *heap* ou d'un *block* √† la zone de donn√©es utilisateur.

```c
#define HEAP_SHIFT(start)   ((void*)start + sizeof(t_heap))
#define BLOCK_SHIFT(start)  ((void*)start + sizeof(t_block))
```

### Strat√©gie De Performance: Toutes Les Allocations Ne Se Valent Pas

J'ai vite compris que traiter de la m√™me mani√®re une allocation de 10 octets et une de 10 m√©gaoctets √©tait une mauvaise id√©e. Pour optimiser, j'ai cr√©√© trois cat√©gories: `TINY`, `SMALL`, et `LARGE`. Ma strat√©gie a √©t√© de pr√©-allouer des pages m√©moires pour les requ√™tes `TINY` et `SMALL`, avec pour objectif de faire tenir au moins 100 blocs dans chaque *heap*. Les blocs `LARGE` sont l'exception; ils sont allou√©s un par un, sans pr√©-allocation, car ils sont g√©n√©ralement plus rares.

Une astuce que j'ai apprise en chemin: il est beaucoup plus efficace de choisir des tailles de *heap* qui soient des multiples de la taille de page du syst√®me. On peut obtenir cette valeur avec `getpagesize()` (ou `getconf PAGE_SIZE` dans le terminal). Sur ma machine, c'est 4096 octets.

J'ai donc fait quelques calculs pour d√©finir mes tailles de *heap*:

```c
// One page can hold 128 tiny blocks
#define  TINY_HEAP_ALLOCATION_SIZE   (4 * getpagesize())
#define  TINY_BLOCK_SIZE             (TINY_HEAP_ALLOCATION_SIZE / 128)

// Four pages can hold 128 small blocks
#define  SMALL_HEAP_ALLOCATION_SIZE  (16 * getpagesize())
#define  SMALL_BLOCK_SIZE            (SMALL_HEAP_ALLOCATION_SIZE / 128)
```

### L'algorithme De `malloc`: Trouver Une place Pour Les Donn√©es

Lorsqu'un appel √† `malloc` survient, voici la logique que suit mon code:

1. Il consulte d'abord un pointeur global pour voir si des *heaps* existent d√©j√†.
2. Il parcourt ensuite la liste des *heaps*, √† la recherche d'un bloc libre suffisamment grand. J'ai utilis√© la strat√©gie du **first-fit**: prendre le premier qui convient. C'est simple et rapide.
3. S'il arrive √† la fin d'un *heap* o√π il reste de la place, il y ajoute simplement un nouveau bloc.
4. Si le dernier *heap* est compl√®tement plein, il est temps de demander plus de "terrain" au syst√®me d'exploitation en appelant `mmap`.

```c
// L'appel syst√®me pour cr√©er un nouveau heap.
void *heap = (t_heap *)mmap(NULL, heap_size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);
```

### `free` Et Le Probl√®me De la Fragmentation

![Memory Fragmentation](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y7xikxHO1Yoyv1eZm7l6aA.png)

Quand `free` est appel√©, il est facile de simplement marquer un bloc comme "disponible", mais cela engendre un probl√®me appel√© la **fragmentation**. On se retrouve avec une multitude de petits trous inutilisables dans la m√©moire, un peu comme une partie de Tetris qui aurait mal tourn√©.

Pour contrer ce ph√©nom√®ne, j'ai mis en ≈ìuvre deux strat√©gies cl√©s:

* **La fusion (*Coalescing*):** Lorsqu'un bloc est lib√©r√©, je v√©rifie si ses voisins sont √©galement libres. Si c'est le cas, je les fusionne en un seul grand bloc libre.
* **La restitution de la m√©moire:** Si le bloc lib√©r√© est le tout dernier d'un *heap* et que j'ai d'autres *heaps* disponibles, je restitue simplement l'int√©gralit√© du *heap* vide au syst√®me d'exploitation avec `munmap`. Inutile de s'accrocher √† de la m√©moire vide.

```c
// Rendre la m√©moire au noyau.
munmap(heap, heap->total_size);
```

### `realloc`: Le M√©tamorphe

`realloc` n'est en r√©alit√© qu'une recette simple: appeler `malloc` pour un nouveau bloc plus grand, copier les donn√©es de l'ancien bloc vers le nouveau avec `memcpy`, et lib√©rer l'ancien bloc avec `free`.

Attention √† un cas particulier: `realloc(ptr, 0)`. Le comportement peut varier ici. J'ai adopt√© une approche "paresseuse" en retournant simplement le pointeur d'origine. Cependant, sachez que certaines normes stipulent que cela devrait √™tre √©quivalent √† `free(ptr)`. Mon conseil: n'utilisez pas `realloc` pour lib√©rer la m√©moire. √Ä chaque outil sa fonction.

## L'√©preuve Du Feu

La partie la plus gratifiante a √©t√© de voir mon `malloc` faire tourner de vrais programmes. J'ai √©crit un petit script pour forcer l'√©diteur de liens dynamique √† charger ma biblioth√®que √† la place de celle du syst√®me.

```sh
#!/bin/sh
export DYLD_LIBRARY_PATH=.
export DYLD_INSERT_LIBRARIES=libft_malloc.so
export DYLD_FORCE_FLAT_NAMESPACE=1
$@
```

En sauvegardant ce script sous `run.sh`, je pouvais lancer des commandes comme `sh run.sh ls -l` ou `sh run.sh vim` et voir si elles fonctionnaient.

### Le Crash De `vim` Et la Le√ßon Sur L'alignement

Bien s√ªr, tout n'a pas fonctionn√© du premier coup. `ls` se lan√ßait sans probl√®me, mais `vim` provoquait imm√©diatement une erreur de segmentation (*segmentation fault*). Que se passait-il?

Le coupable: **l'alignement de la m√©moire**. Il s'est av√©r√© que le `malloc` standard de macOS (o√π je faisais mes tests) ne retourne pas n'importe quel pointeur. Il garantit que l'adresse retourn√©e est un multiple de 16. Certains programmes et instructions en d√©pendent pour des raisons de performance. Mon `malloc` ne le faisait pas, et `vim` plantait.

La solution fut une astuce binaire simple mais puissante: `size = (size + 15) & ~15;`. Cette unique ligne de code assure que la taille est toujours un multiple de 16, et donc que l'adresse retourn√©e sera correctement align√©e. Une le√ßon cruciale, apprise √† la dure.

Et voil√† pour l'aventure! Nous sommes partis de l'appel syst√®me `mmap` pour arriver √† une biblioth√®que `malloc` fonctionnelle et test√©e. Pour moi, ce projet n'√©tait pas qu'une affaire de code; il s'agissait de d√©mystifier un m√©canisme au c≈ìur du fonctionnement de nos machines.

La pratique est essentielle. Si vous voulez creuser le sujet, n'h√©sitez pas √† consulter [l'impl√©mentation compl√®te sur mon GitHub](https://github.com/jterrazz/42-malloc). Forkez-le, cassez-le, am√©liorez-le. Comprendre les fondations, c'est se donner le pouvoir de tout construire. Happy coding
